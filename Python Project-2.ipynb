{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ca0b9d97",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x87 in position 10: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Input \u001b[1;32mIn [38]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# STEP 1: Reading Data\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m table1 \u001b[38;5;241m=\u001b[39m \u001b[43mpandas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcustomer_details.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m table2 \u001b[38;5;241m=\u001b[39m pandas\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcustomer_policy_details.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(table1\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:586\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    571\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    572\u001b[0m     dialect,\n\u001b[0;32m    573\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    582\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    583\u001b[0m )\n\u001b[0;32m    584\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 586\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:482\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    479\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    481\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 482\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    484\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    485\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:811\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwds:\n\u001b[0;32m    809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 811\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1040\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1036\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1037\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown engine: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mengine\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (valid options are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmapping\u001b[38;5;241m.\u001b[39mkeys()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1038\u001b[0m     )\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;66;03m# error: Too many arguments for \"ParserBase\"\u001b[39;00m\n\u001b[1;32m-> 1040\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mapping[engine](\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:69\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     67\u001b[0m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m ensure_dtype_objs(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 69\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m parsers\u001b[38;5;241m.\u001b[39mTextReader(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:542\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:642\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:843\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:1917\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x87 in position 10: invalid start byte"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas\n",
    "table1 = pandas.read_csv(\"customer_details.csv\")\n",
    "table2 = pandas.read_csv(\"customer_policy_details.csv\")\n",
    "print(table1.head())\n",
    "print(table2.head())\n",
    "table1_labels={'0':'customer_id', '1':'gender', '2':'age', '3':'driving_licence_presence',\n",
    "'4':'region_code', '5':'previously_insured', '6':'vehicle_age', '7':'vehicle_damage'}\n",
    "table2_labels={'0':'customer_id', '1':'annual_premium_INR', '2':'sales_channel_code', '3':'vintage',\n",
    "'4':'response'}\n",
    "\n",
    "for i in range(table1.shape[1]):\n",
    "    print(f\"number of cells of {table1_labels[str(i)]} with null values = {table1[str(i)].isnull().sum()}\")\n",
    "\n",
    "table1.info()\n",
    "\n",
    "table1.dropna(subset=['0'],inplace=True)\n",
    "print(f\"number of cells of {table1_labels[str(0)]} with null values = {table1[str(0)].isnull().sum()}\")\n",
    "\n",
    "for i in range(2,6):\n",
    "    table1[str(i)].fillna(table1[str(i)].mean(),inplace=True)\n",
    "    print(f\"number of cells of {table1_labels[str(i)]} with null values = {table1[str(i)].isnull().sum()}\")\n",
    "\n",
    "for i in [1,6,7]:\n",
    "    table1[str(i)].fillna(table1[str(i)].mode()[0],inplace=True)\n",
    "    print(f\"number of cells of {table1_labels[str(i)]} with null values = {table1[str(i)].isnull().sum()}\")\n",
    "\n",
    "for i in range(table2.shape[1]):\n",
    "    print(f\"number of cells of {table2_labels[str(i)]} with null values is {table2[str(i)].isnull().sum()}\")\n",
    "table2.info()\n",
    "\n",
    "table2.dropna(subset=['0'],inplace=True)\n",
    "print(f\"number of cells of {table1_labels[str(0)]} with null values = {table2[str(0)].isnull().sum()}\")\n",
    "\n",
    "for i in range(1,5):\n",
    "    table2[str(i)].fillna(table2[str(i)].mean(),inplace=True)\n",
    "    print(f\"number of cells of {table2_labels[str(i)]} with null values = {table2[str(i)].isnull().sum()}\")\n",
    "\n",
    "table1_limits = {}\n",
    "for i in range(2,6):\n",
    "    computations = table1[str(i)].describe(percentiles=[.25, .75])\n",
    "    mean = computations.values[1]\n",
    "    Q1 = computations.values[4] # 25%\n",
    "    Q3 = computations.values[6] # 75%\n",
    "    IQR = Q3-Q1\n",
    "    ll = Q1 - 1.5*IQR # lower limit\n",
    "    hl = Q3 + 1.5*IQR # higher limit\n",
    "    table1_limits[str(i)] = (ll,hl)\n",
    "table1_limits\n",
    "\n",
    "table1_outliers = {'2':0, '3':0, '4':0, '5':0}\n",
    "\n",
    "for j in table1.index:\n",
    "    for i in range(2,6):\n",
    "        if (table1_limits[str(i)][0]!=table1_limits[str(i)][1]) and (table1.loc[j, str(i)]>table1_limits[str(i)][1] or table1.loc[j, str(i)]<table1_limits[str(i)][0]):\n",
    "            table1_outliers[str(i)]+=1\n",
    "\n",
    "table1_outliers\n",
    "\n",
    "for j in table1.index:\n",
    "    for i in range(2,6):\n",
    "        if table1.loc[j, str(i)]<table1_limits[str(i)][0]:\n",
    "            table1.loc[j, str(i)]=table1[str(i)].mean()\n",
    "        if table1.loc[j, str(i)]>table1_limits[str(i)][1]:\n",
    "            table1.loc[j, str(i)]=table1[str(i)].mean()\n",
    "table2_limits = {}\n",
    "\n",
    "for i in range(1,5):\n",
    "    computations = table2[str(i)].describe(percentiles=[.25, .75])\n",
    "    mean = computations.values[1]\n",
    "    Q1 = computations.values[4] # 25%\n",
    "    Q3 = computations.values[6] # 75%\n",
    "    IQR = Q3-Q1\n",
    "    ll = Q1 - 1.5*IQR # lower limit\n",
    "    hl = Q3 + 1.5*IQR # higher limit\n",
    "    table2_limits[str(i)] = (ll,hl)\n",
    "table2_limits\n",
    " \n",
    "table2_outliers = {'1':0, '2':0, '3':0, '4':0, '5':0}\n",
    "\n",
    "for j in table2.index:\n",
    "    for i in range(1,5):\n",
    "        if (table2_limits[str(i)][0]!=table2_limits[str(i)][1]) and (table2.loc[j, str(i)]>table2_limits[str(i)][1] or table2.loc[j, str(i)]<table2_limits[str(i)][0]):\n",
    "            table2_outliers[str(i)]+=1\n",
    "\n",
    "table2_outliers\n",
    "\n",
    "for j in table2.index:\n",
    "    for i in range(1,5):\n",
    "        if table2.loc[j, str(i)]<table2_limits[str(i)][0]:\n",
    "            table2.loc[j, str(i)]=table2[str(i)].mean()\n",
    "        if table2.loc[j, str(i)]>table2_limits[str(i)][1]:\n",
    "            table2.loc[j, str(i)]=table2[str(i)].mean()\n",
    "\n",
    "table1.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "\n",
    "table2.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "\n",
    "table1.apply(lambda x: x.str.lower() if x.dtype == \"object\" else x)\n",
    "\n",
    "table2.apply(lambda x: x.str.lower() if x.dtype == \"object\" else x)\n",
    "\n",
    "table1.drop_duplicates(inplace=True)\n",
    "\n",
    "table2.drop_duplicates(inplace=True)\n",
    " \n",
    "\n",
    "data = pandas.merge(table1, table2, on='0',)\n",
    "labels={'0':'customer_id', '1_x':'gender', '2_x':'age', '3_x':'driving_licence_presence',\n",
    "'4_x':'region_code', '5':'previously_insured', '6':'vehicle_age', '7':'vehicle_damage',\n",
    "'1_y':'annual_premium_INR', '2_y':'sales_channel_code', '3_y':'vintage', '4_y':'response'}\n",
    "data.rename(columns=labels, inplace=True)\n",
    "data\n",
    "\n",
    "data.groupby('gender')['annual_premium_INR'].mean()\n",
    " \n",
    "\n",
    "result4_2 = data.groupby('age')['annual_premium_INR'].mean()\n",
    "\n",
    "import matplotlib.pyplot as pyplot\n",
    "result4_2.plot()\n",
    "pyplot.show()\n",
    "\n",
    "print(f\"male to female ration is {round(data['gender'].value_counts()[0]/data['gender'].value_counts()[1],2)}\")\n",
    "print(f\"generally, the standard is: \\n balanced data ratio: {50/50}\\n slightly balanced data ratio: {round(55/45,2)}-{60/40} \\n imbalanced data ratio: {80/20}-{90/10}\")\n",
    "\n",
    "result4_4 = data.groupby('vehicle_age')['annual_premium_INR'].mean()\n",
    "import matplotlib.pyplot as pyplot\n",
    "result4_4.plot()\n",
    "pyplot.show()\n",
    "\n",
    "n = data['age'].corr(data['annual_premium_INR'])\n",
    "if n<-0.5:\n",
    "    print(\"Strong negative relationship\")\n",
    "if n>0.5:\n",
    "    print(\"Strong positive relationship\")\n",
    "if n>-0.5 and n<0.5:\n",
    "    print(\"There is no relationship!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6aa4bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6b2324",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
